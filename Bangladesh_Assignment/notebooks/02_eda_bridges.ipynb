{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18d8949c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['road', 'km', 'type', 'LRPName', 'name', 'length', 'condition',\n",
      "       'structureNr', 'roadName', 'chainage', 'width', 'constructionYear',\n",
      "       'spans', 'zone', 'circle', 'division', 'sub-division', 'lat', 'lon',\n",
      "       'EstimatedLoc'],\n",
      "      dtype='object')\n",
      "  road     km              type  LRPName               name  length condition  \\\n",
      "0   N1  1.800       Box Culvert  LRP001a                  .   11.30         A   \n",
      "1   N1  4.925       Box Culvert  LRP004b                  .    6.60         A   \n",
      "2   N1  8.976  PC Girder Bridge  LRP008b  Kanch pur Bridge.  394.23         A   \n",
      "\n",
      "   structureNr                                           roadName chainage  \\\n",
      "0       117861  Dhaka (Jatrabari)-Comilla (Mainamati)-Chittago...      1.8   \n",
      "1       117862  Dhaka (Jatrabari)-Comilla (Mainamati)-Chittago...    4.925   \n",
      "2       119889  Dhaka (Jatrabari)-Comilla (Mainamati)-Chittago...    8.976   \n",
      "\n",
      "   width  constructionYear  spans   zone circle     division   sub-division  \\\n",
      "0   19.5            2005.0    2.0  Dhaka  Dhaka  Narayanganj  Narayanganj-1   \n",
      "1   35.4            2006.0    1.0  Dhaka  Dhaka  Narayanganj  Narayanganj-1   \n",
      "2    NaN               NaN    NaN  Dhaka  Dhaka  Narayanganj  Narayanganj-1   \n",
      "\n",
      "         lat        lon  EstimatedLoc  \n",
      "0  23.702889  90.450389          bcs1  \n",
      "1  23.693611  90.478833          bcs1  \n",
      "2  23.704583  90.518833  road_precise  \n",
      "rows: 21407\n"
     ]
    }
   ],
   "source": [
    "df_bridges = pd.read_excel(\"../data/raw/BMMS_overview.xlsx\")\n",
    "print(df_bridges.columns)\n",
    "print(df_bridges.head(3))\n",
    "print(\"rows:\", len(df_bridges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb7f4ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>road</th>\n",
       "      <th>km</th>\n",
       "      <th>type</th>\n",
       "      <th>LRPName</th>\n",
       "      <th>name</th>\n",
       "      <th>length</th>\n",
       "      <th>condition</th>\n",
       "      <th>structureNr</th>\n",
       "      <th>roadName</th>\n",
       "      <th>chainage</th>\n",
       "      <th>width</th>\n",
       "      <th>constructionYear</th>\n",
       "      <th>spans</th>\n",
       "      <th>zone</th>\n",
       "      <th>circle</th>\n",
       "      <th>division</th>\n",
       "      <th>sub-division</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>EstimatedLoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N1</td>\n",
       "      <td>1.800</td>\n",
       "      <td>Box Culvert</td>\n",
       "      <td>LRP001a</td>\n",
       "      <td>.</td>\n",
       "      <td>11.30</td>\n",
       "      <td>A</td>\n",
       "      <td>117861</td>\n",
       "      <td>Dhaka (Jatrabari)-Comilla (Mainamati)-Chittago...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>19.5</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Narayanganj</td>\n",
       "      <td>Narayanganj-1</td>\n",
       "      <td>23.702889</td>\n",
       "      <td>90.450389</td>\n",
       "      <td>bcs1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N1</td>\n",
       "      <td>4.925</td>\n",
       "      <td>Box Culvert</td>\n",
       "      <td>LRP004b</td>\n",
       "      <td>.</td>\n",
       "      <td>6.60</td>\n",
       "      <td>A</td>\n",
       "      <td>117862</td>\n",
       "      <td>Dhaka (Jatrabari)-Comilla (Mainamati)-Chittago...</td>\n",
       "      <td>4.925</td>\n",
       "      <td>35.4</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Narayanganj</td>\n",
       "      <td>Narayanganj-1</td>\n",
       "      <td>23.693611</td>\n",
       "      <td>90.478833</td>\n",
       "      <td>bcs1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N1</td>\n",
       "      <td>8.976</td>\n",
       "      <td>PC Girder Bridge</td>\n",
       "      <td>LRP008b</td>\n",
       "      <td>Kanch pur Bridge.</td>\n",
       "      <td>394.23</td>\n",
       "      <td>A</td>\n",
       "      <td>119889</td>\n",
       "      <td>Dhaka (Jatrabari)-Comilla (Mainamati)-Chittago...</td>\n",
       "      <td>8.976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Narayanganj</td>\n",
       "      <td>Narayanganj-1</td>\n",
       "      <td>23.704583</td>\n",
       "      <td>90.518833</td>\n",
       "      <td>road_precise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N1</td>\n",
       "      <td>10.880</td>\n",
       "      <td>Box Culvert</td>\n",
       "      <td>LRP010b</td>\n",
       "      <td>NOYAPARA CULVERT</td>\n",
       "      <td>6.30</td>\n",
       "      <td>A</td>\n",
       "      <td>112531</td>\n",
       "      <td>Dhaka (Jatrabari)-Comilla (Mainamati)-Chittago...</td>\n",
       "      <td>10.88</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Narayanganj</td>\n",
       "      <td>Vitikandi</td>\n",
       "      <td>23.699833</td>\n",
       "      <td>90.530722</td>\n",
       "      <td>bcs1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N1</td>\n",
       "      <td>10.897</td>\n",
       "      <td>Box Culvert</td>\n",
       "      <td>LRP010c</td>\n",
       "      <td>ADUPUR CULVERT</td>\n",
       "      <td>6.30</td>\n",
       "      <td>A</td>\n",
       "      <td>112532</td>\n",
       "      <td>Dhaka (Jatrabari)-Comilla (Mainamati)-Chittago...</td>\n",
       "      <td>10.897</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Narayanganj</td>\n",
       "      <td>Vitikandi</td>\n",
       "      <td>23.699667</td>\n",
       "      <td>90.530722</td>\n",
       "      <td>bcs1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  road      km              type  LRPName               name  length  \\\n",
       "0   N1   1.800       Box Culvert  LRP001a                  .   11.30   \n",
       "1   N1   4.925       Box Culvert  LRP004b                  .    6.60   \n",
       "2   N1   8.976  PC Girder Bridge  LRP008b  Kanch pur Bridge.  394.23   \n",
       "3   N1  10.880       Box Culvert  LRP010b   NOYAPARA CULVERT    6.30   \n",
       "4   N1  10.897       Box Culvert  LRP010c     ADUPUR CULVERT    6.30   \n",
       "\n",
       "  condition  structureNr                                           roadName  \\\n",
       "0         A       117861  Dhaka (Jatrabari)-Comilla (Mainamati)-Chittago...   \n",
       "1         A       117862  Dhaka (Jatrabari)-Comilla (Mainamati)-Chittago...   \n",
       "2         A       119889  Dhaka (Jatrabari)-Comilla (Mainamati)-Chittago...   \n",
       "3         A       112531  Dhaka (Jatrabari)-Comilla (Mainamati)-Chittago...   \n",
       "4         A       112532  Dhaka (Jatrabari)-Comilla (Mainamati)-Chittago...   \n",
       "\n",
       "  chainage  width  constructionYear  spans   zone circle     division  \\\n",
       "0      1.8   19.5            2005.0    2.0  Dhaka  Dhaka  Narayanganj   \n",
       "1    4.925   35.4            2006.0    1.0  Dhaka  Dhaka  Narayanganj   \n",
       "2    8.976    NaN               NaN    NaN  Dhaka  Dhaka  Narayanganj   \n",
       "3    10.88   12.2            1992.0    2.0  Dhaka  Dhaka  Narayanganj   \n",
       "4   10.897   12.2            1984.0    2.0  Dhaka  Dhaka  Narayanganj   \n",
       "\n",
       "    sub-division        lat        lon  EstimatedLoc  \n",
       "0  Narayanganj-1  23.702889  90.450389          bcs1  \n",
       "1  Narayanganj-1  23.693611  90.478833          bcs1  \n",
       "2  Narayanganj-1  23.704583  90.518833  road_precise  \n",
       "3      Vitikandi  23.699833  90.530722          bcs1  \n",
       "4      Vitikandi  23.699667  90.530722          bcs1  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bridges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1b8ab78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>km</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21406.000000</td>\n",
       "      <td>21313.000000</td>\n",
       "      <td>21313.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.217405</td>\n",
       "      <td>23.828505</td>\n",
       "      <td>90.227328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>78.810955</td>\n",
       "      <td>2.247895</td>\n",
       "      <td>3.364169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.207250</td>\n",
       "      <td>22.942527</td>\n",
       "      <td>89.377806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.147000</td>\n",
       "      <td>23.823743</td>\n",
       "      <td>90.289194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.012250</td>\n",
       "      <td>24.720939</td>\n",
       "      <td>91.288417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>522.718000</td>\n",
       "      <td>91.544194</td>\n",
       "      <td>93.298416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 km           lat           lon\n",
       "count  21406.000000  21313.000000  21313.000000\n",
       "mean      41.217405     23.828505     90.227328\n",
       "std       78.810955      2.247895      3.364169\n",
       "min        0.000000      0.000000      0.000000\n",
       "25%        6.207250     22.942527     89.377806\n",
       "50%       15.147000     23.823743     90.289194\n",
       "75%       35.012250     24.720939     91.288417\n",
       "max      522.718000     91.544194     93.298416"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bridges[[\"km\",\"lat\",\"lon\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "062e811e",
   "metadata": {},
   "outputs": [
    {
     "ename": "_IncompleteInputError",
     "evalue": "incomplete input (32252400.py, line 19)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdf.loc[mask_zero, ['']\u001b[39m\n                          ^\n\u001b[31m_IncompleteInputError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "#dit is eig cluster 1: de bridges met sws verkeerde waardes \n",
    "# 1) Missing coords (NAN values)\n",
    "mask_missing = df_bridges[\"lat\"].isna() | df_bridges[\"lon\"].isna() \n",
    "#--> oplossing: kijken in de andere data sets of het daar wel in staat? je weet wel weg waar op zou staan\n",
    "\n",
    "# 2) Zero coords (0 or 0.0)\n",
    "mask_zero = (df_bridges[\"lat\"] == 0) | (df_bridges[\"lon\"] == 0) \n",
    "\n",
    "\n",
    "# 3) Invalid range coords\n",
    "mask_invalid = (df[\"lat\"] < -90) | (df[\"lat\"] > 90) | (df[\"lon\"] < -180) | (df[\"lon\"] > 180)\n",
    "\n",
    "print(\"Missing:\", mask_missing.sum())\n",
    "print(\"Zero:\", mask_zero.sum())\n",
    "print(\"Invalid:\", mask_invalid.sum())\n",
    "\n",
    "# (optioneel) laat voorbeelden zien\n",
    "df.loc[mask_invalid, [\"road\", \"km\", \"lat\", \"lon\"]].head(10) #dit zijn maar kleine fouten net boven 91 graden niet te veel aandacht aan? \n",
    "df.loc[mask_zero, ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faaa32a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1caa236f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m LAT_MIN, LAT_MAX = \u001b[32m20.5\u001b[39m, \u001b[32m26.8\u001b[39m\n\u001b[32m      2\u001b[39m LON_MIN, LON_MAX = \u001b[32m88.0\u001b[39m, \u001b[32m92.8\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m out_country = \u001b[43mdf\u001b[49m[\n\u001b[32m      5\u001b[39m     (df[\u001b[33m\"\u001b[39m\u001b[33mlat\u001b[39m\u001b[33m\"\u001b[39m].notna()) &\n\u001b[32m      6\u001b[39m     (df[\u001b[33m\"\u001b[39m\u001b[33mlon\u001b[39m\u001b[33m\"\u001b[39m].notna()) &\n\u001b[32m      7\u001b[39m     (\n\u001b[32m      8\u001b[39m         (df[\u001b[33m\"\u001b[39m\u001b[33mlat\u001b[39m\u001b[33m\"\u001b[39m] < LAT_MIN) |\n\u001b[32m      9\u001b[39m         (df[\u001b[33m\"\u001b[39m\u001b[33mlat\u001b[39m\u001b[33m\"\u001b[39m] > LAT_MAX) |\n\u001b[32m     10\u001b[39m         (df[\u001b[33m\"\u001b[39m\u001b[33mlon\u001b[39m\u001b[33m\"\u001b[39m] < LON_MIN) |\n\u001b[32m     11\u001b[39m         (df[\u001b[33m\"\u001b[39m\u001b[33mlon\u001b[39m\u001b[33m\"\u001b[39m] > LON_MAX)\n\u001b[32m     12\u001b[39m     )\n\u001b[32m     13\u001b[39m ]\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOutside Bangladesh:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(out_country)) \n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "LAT_MIN, LAT_MAX = 20.5, 26.8\n",
    "LON_MIN, LON_MAX = 88.0, 92.8\n",
    "\n",
    "out_country = df[\n",
    "    (df[\"lat\"].notna()) &\n",
    "    (df[\"lon\"].notna()) &\n",
    "    (\n",
    "        (df[\"lat\"] < LAT_MIN) |\n",
    "        (df[\"lat\"] > LAT_MAX) |\n",
    "        (df[\"lon\"] < LON_MIN) |\n",
    "        (df[\"lon\"] > LON_MAX)\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Outside Bangladesh:\", len(out_country)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "889daf78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['road', 'km', 'type', 'LRPName', 'name', 'length', 'condition',\n",
       "       'structureNr', 'roadName', 'chainage', 'width', 'constructionYear',\n",
       "       'spans', 'zone', 'circle', 'division', 'sub-division', 'lat', 'lon',\n",
       "       'EstimatedLoc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaned df = clean csv \n",
    "df_cleaned_roads = pd.read_csv(\"../data/raw/clean.csv\") \n",
    "df_cleaned_roads.head()   \n",
    "df_bridges.columns\n",
    "\n",
    "#match them on road and LRP name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "17168ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'road', 'chainage', 'lrp', 'lat', 'lon', 'gap', 'type',\n",
       "       'name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned_roads.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "13a9e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(s):\n",
    "    return s.astype(str).str.strip().str.upper()\n",
    "\n",
    "# Normalised keys\n",
    "df_roads = df_cleaned_roads.copy()\n",
    "df_br = df_bridges.copy()\n",
    "\n",
    "df_roads[\"road_norm\"] = norm(df_roads[\"road\"])\n",
    "df_roads[\"lrp_norm\"]  = norm(df_roads[\"lrp\"])\n",
    "\n",
    "df_br[\"road_norm\"] = norm(df_br[\"road\"])\n",
    "df_br[\"lrp_norm\"]  = norm(df_br[\"LRPName\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "485efc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_br.describe has: 21407 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd4baf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_roads.describe has: #52210 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5029c313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bridges (BMMS) missing in roads: 6552\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>road_norm</th>\n",
       "      <th>lrp_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N1</td>\n",
       "      <td>LRP001A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N1</td>\n",
       "      <td>LRP004B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>N1</td>\n",
       "      <td>LRP013B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>N1</td>\n",
       "      <td>LRP014A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>N1</td>\n",
       "      <td>LRP018C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>N1</td>\n",
       "      <td>LRP021C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>N1</td>\n",
       "      <td>LRP021D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>N1</td>\n",
       "      <td>LRP021C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>N1</td>\n",
       "      <td>LRP023D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>N1</td>\n",
       "      <td>LRP023C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>N1</td>\n",
       "      <td>LRP023C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>N1</td>\n",
       "      <td>LRP032B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>N1</td>\n",
       "      <td>LRP032D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>N1</td>\n",
       "      <td>LRP032E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>N1</td>\n",
       "      <td>LRP032D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>N1</td>\n",
       "      <td>LRP032D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>N1</td>\n",
       "      <td>LRP034A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>N1</td>\n",
       "      <td>LRP034A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>N1</td>\n",
       "      <td>LRP034A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>N1</td>\n",
       "      <td>LRP034B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   road_norm lrp_norm\n",
       "0         N1  LRP001A\n",
       "1         N1  LRP004B\n",
       "11        N1  LRP013B\n",
       "12        N1  LRP014A\n",
       "15        N1  LRP018C\n",
       "17        N1  LRP021C\n",
       "18        N1  LRP021D\n",
       "19        N1  LRP021C\n",
       "21        N1  LRP023D\n",
       "22        N1  LRP023C\n",
       "23        N1  LRP023C\n",
       "40        N1  LRP032B\n",
       "43        N1  LRP032D\n",
       "44        N1  LRP032E\n",
       "45        N1  LRP032D\n",
       "46        N1  LRP032D\n",
       "49        N1  LRP034A\n",
       "50        N1  LRP034A\n",
       "51        N1  LRP034A\n",
       "52        N1  LRP034B"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cluster 2 bridges die niet in road file zitten \n",
    "#bridges missing in roads; #dus bridge zegt dat het op bepaalde road ligt maar code komt niet overeen met een \n",
    "#LRP code op die road \n",
    "bridge_keys = df_br[[\"road_norm\",\"lrp_norm\"]]\n",
    "road_keys   = df_roads[[\"road_norm\",\"lrp_norm\"]]\n",
    "\n",
    "bridges_missing_in_roads = bridge_keys.merge(\n",
    "    road_keys, on=[\"road_norm\",\"lrp_norm\"], how=\"left\", indicator=True\n",
    ").query(\"_merge == 'left_only'\").drop(columns=\"_merge\")\n",
    "\n",
    "print(\"Bridges (BMMS) missing in roads:\", len(bridges_missing_in_roads))\n",
    "bridges_missing_in_roads.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b55b187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wat ik nu nodig heb: outlier file (groupering dus wat Yoran geinterpoleerd heeft) \n",
    "#--> die interpolatie dan aanpssen de lon en lat? in bridge file? Maar wat als ze wel goed stonden in bridge file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68281cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ik ga ze nu overlappen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a56772ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eerst ff distance functie hier zetten hebben we later nodig: \n",
    "def haversine_dist(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000  # Straal aarde in meters\n",
    "    phi1, phi2 = np.radians(lat1), np.radians(lat2)\n",
    "    dphi = np.radians(lat2 - lat1)\n",
    "    dlambda = np.radians(lon2 - lon1)\n",
    "    a = np.sin(dphi / 2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(dlambda / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0c89a606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wegen geladen: 52210\n",
      "Bruggen geladen: 21407\n"
     ]
    }
   ],
   "source": [
    "#inladen: \n",
    "# 1. Laad de SCHONE wegen (output van notebook 1)\n",
    "# Pas het pad aan naar waar jij je clean.csv hebt opgeslagen\n",
    "df_roads = pd.read_csv(\"../data/raw/clean.csv\")  \n",
    "\n",
    "# 2. Laad de RUWE bruggen\n",
    "df_bridges = pd.read_excel(\"../data/raw/BMMS_overview.xlsx\")\n",
    "\n",
    "# Zorg dat de koppel-kolommen nummers zijn\n",
    "df_roads['chainage'] = pd.to_numeric(df_roads['chainage'], errors='coerce')\n",
    "df_bridges['km'] = pd.to_numeric(df_bridges['km'], errors='coerce')\n",
    "\n",
    "# Zorg dat coordinaten nummers zijn #cooerce zorgt ervoor dat als iets niet goed staat niet verwijdert wordt maar  \n",
    "#nan value wordt: dus wellicht later nog kijken!! wlke dit waren en of dit typoos waren \n",
    "for c in ['lat', 'lon']:\n",
    "    df_roads[c] = pd.to_numeric(df_roads[c], errors='coerce')\n",
    "    df_bridges[c] = pd.to_numeric(df_bridges[c], errors='coerce')\n",
    "\n",
    "print(f\"Wegen geladen: {len(df_roads)}\")\n",
    "print(f\"Bruggen geladen: {len(df_bridges)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b71385ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bezig met berekenen van offsets (dit duurt even)...\n",
      "\n",
      "=== DATA QUALITY DIAGNOSE ===\n",
      "error_flag\n",
      "OK                        12221\n",
      "Small Offset (50-500m)     8739\n",
      "Large Offset (>20000m)      312\n",
      "Bad GPS (Africa/Null)       135\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Aantal bruggen die voorbij einde weg liggen (Clamped): 411\n"
     ]
    }
   ],
   "source": [
    "df_analysis = df_bridges.copy()\n",
    "\n",
    "# Nieuwe kolommen aanmaken\n",
    "df_analysis['ideal_lat'] = np.nan\n",
    "df_analysis['ideal_lon'] = np.nan\n",
    "df_analysis['offset_meters'] = np.nan\n",
    "df_analysis['error_flag'] = 'OK' # Startwaarde\n",
    "\n",
    "# Lijst van bekende wegen\n",
    "known_roads = df_analysis.loc[df_analysis['road'].isin(unique_roads), 'road'].unique()\n",
    "\n",
    "print(\"Bezig met berekenen van offsets (dit duurt even)...\")\n",
    "\n",
    "for road_id in known_roads:\n",
    "    # 1. Pak de weg data (Cleaned)\n",
    "    road_data = df_roads[df_roads['road'] == road_id].sort_values('chainage')\n",
    "    if road_data.empty: continue\n",
    "        \n",
    "    # 2. Pak de bruggen op deze weg\n",
    "    mask = df_analysis['road'] == road_id\n",
    "    bridge_kms = df_analysis.loc[mask, 'km']\n",
    "    \n",
    "    # 3. BEREKEN IDEALE LOCATIE (Interpolatie op chainage)\n",
    "    # Dit is de \"waarheid\" volgens de chainage\n",
    "    ideal_lats = np.interp(bridge_kms, road_data['chainage'], road_data['lat'])\n",
    "    ideal_lons = np.interp(bridge_kms, road_data['chainage'], road_data['lon'])\n",
    "    \n",
    "    df_analysis.loc[mask, 'ideal_lat'] = ideal_lats\n",
    "    df_analysis.loc[mask, 'ideal_lon'] = ideal_lons\n",
    "    \n",
    "    # 4. Check of brug \"voorbij\" de weg ligt (Clamping nodig?)\n",
    "    max_len = road_data['chainage'].max()\n",
    "    clamped_mask = mask & (bridge_kms > max_len)\n",
    "    df_analysis.loc[clamped_mask, 'is_clamped'] = True\n",
    "\n",
    "# --- FLAGS TOEWIJZEN ---\n",
    "\n",
    "# Stap A: Bereken afstand (alleen als GPS bestaat)\n",
    "# Haversine tussen Huidige GPS en Ideale Locatie\n",
    "dists = haversine_dist(\n",
    "    df_analysis['lat'], df_analysis['lon'],\n",
    "    df_analysis['ideal_lat'], df_analysis['ideal_lon']\n",
    ")\n",
    "df_analysis['offset_meters'] = dists\n",
    "\n",
    "# Stap B: Categorieën bepalen\n",
    "\n",
    "# 1. Onbekende weg\n",
    "df_analysis.loc[~df_analysis['road'].isin(unique_roads), 'error_flag'] = 'Unknown Road'\n",
    "\n",
    "# 2. GPS Missing of in Afrika/Oceaan (Bounding box check)\n",
    "bad_gps = (df_analysis['lat'].isna()) | (df_analysis['lat'] < 20) | (df_analysis['lat'] > 27)\n",
    "df_analysis.loc[bad_gps, 'error_flag'] = 'Bad GPS (Africa/Null)'\n",
    "\n",
    "# 3. Grote Offset (>20000m) - Waarschijnlijk verkeerde weg of slechte GPS\n",
    "large_offset = (~bad_gps) & (df_analysis['offset_meters'] > 20000) #welke treshold \n",
    "df_analysis.loc[large_offset, 'error_flag'] = 'Large Offset (>20000m)'\n",
    "\n",
    "# 4. Kleine Offset (50-500m) - Onnauwkeurigheid\n",
    "small_offset = (~bad_gps) & (df_analysis['offset_meters'] >= 50) & (df_analysis['offset_meters'] <= 500)\n",
    "df_analysis.loc[small_offset, 'error_flag'] = 'Small Offset (50-500m)'\n",
    "\n",
    "# Print resultaten voor je rapport\n",
    "print(\"\\n=== DATA QUALITY DIAGNOSE ===\")\n",
    "print(df_analysis['error_flag'].value_counts())\n",
    "print(f\"\\nAantal bruggen die voorbij einde weg liggen (Clamped): {df_analysis['is_clamped'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a24de68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GPS KWALITEIT ANALYSE ===\n",
      "gps_status\n",
      "Valid                     21270\n",
      "Missing (NaN)                94\n",
      "Out of Bounds (Africa)       26\n",
      "Zero Coordinates (0,0)       17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Start Hybride Match...\n",
      "Aantal bruggen gematcht op LRP Naam (Gouden standaard): 14912\n",
      "Aantal bruggen NIET gematcht op naam (Terugvallen op KM): 6552\n",
      "\n",
      "Aantal bruggen waar KM fout was, maar LRP naam ons redde: 2828\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Laden & Schoonmaken\n",
    "\n",
    "\n",
    "# Strings standaardiseren (BELANGRIJK voor matchen)\n",
    "# In de road file heet de kolom 'lrp', in BMMS heet hij 'LRPName'\n",
    "df_roads['road'] = df_roads['road'].astype(str).str.strip().str.upper()\n",
    "df_roads['lrp'] = df_roads['lrp'].astype(str).str.strip().str.upper()\n",
    "\n",
    "df_bridges['road'] = df_bridges['road'].astype(str).str.strip().str.upper()\n",
    "df_bridges['LRPName'] = df_bridges['LRPName'].astype(str).str.strip().str.upper()\n",
    "\n",
    "# Nummers\n",
    "for c in ['chainage', 'lat', 'lon']: df_roads[c] = pd.to_numeric(df_roads[c], errors='coerce')\n",
    "for c in ['km', 'lat', 'lon']: df_bridges[c] = pd.to_numeric(df_bridges[c], errors='coerce')\n",
    "\n",
    "# --- STAP A: ONDERSCHEID MAKEN TUSSEN FOUTTYPES (Null vs Africa) ---\n",
    "# We maken specifieke categorieën aan\n",
    "df_bridges['gps_status'] = 'Valid' # Startwaarde\n",
    "\n",
    "# 1. Null / NaN (Helemaal geen data)\n",
    "mask_null = df_bridges['lat'].isna() | df_bridges['lon'].isna()\n",
    "df_bridges.loc[mask_null, 'gps_status'] = 'Missing (NaN)'\n",
    "\n",
    "# 2. Nul-waarden (0,0 -> ligt in de oceaan bij Afrika)\n",
    "mask_zero = (df_bridges['lat'] == 0) & (df_bridges['lon'] == 0)\n",
    "df_bridges.loc[mask_zero, 'gps_status'] = 'Zero Coordinates (0,0)'\n",
    "\n",
    "# 3. Afrika / Buitenland (Wel cijfers, maar verkeerde plek)\n",
    "# Alles buiten Lat 20-27 en Lon 88-93\n",
    "mask_africa = (\n",
    "    (df_bridges['gps_status'] == 'Valid') & \n",
    "    ((df_bridges['lat'] < 20) | (df_bridges['lat'] > 27) | \n",
    "     (df_bridges['lon'] < 88) | (df_bridges['lon'] > 93))\n",
    ")\n",
    "df_bridges.loc[mask_africa, 'gps_status'] = 'Out of Bounds (Africa)'\n",
    "\n",
    "print(\"=== GPS KWALITEIT ANALYSE ===\")\n",
    "print(df_bridges['gps_status'].value_counts())\n",
    "\n",
    "\n",
    "# --- STAP B: DE HYBRIDE MATCH (LRP Eerst, dan KM) ---\n",
    "print(\"\\nStart Hybride Match...\")\n",
    "\n",
    "# We gaan proberen de brug te koppelen aan de Road-data via ROAD + LRP NAAM\n",
    "# We noemen de kolommen van roads even anders om verwarring te voorkomen\n",
    "roads_lrp_lookup = df_roads[['road', 'lrp', 'lat', 'lon', 'chainage']].rename(\n",
    "    columns={'lrp': 'LRPName', 'lat': 'road_lat', 'lon': 'road_lon', 'chainage': 'road_chainage'}\n",
    ")\n",
    "\n",
    "# Merge: We plakken de road-info aan de brug VAST als de naam matcht\n",
    "# 'left' merge betekent: houd alle bruggen, zoek road info erbij\n",
    "df_merged = df_bridges.merge(roads_lrp_lookup, on=['road', 'LRPName'], how='left')\n",
    "\n",
    "# Nu hebben we bruggen MET en ZONDER match\n",
    "mask_match = ~df_merged['road_lat'].isna()\n",
    "print(f\"Aantal bruggen gematcht op LRP Naam (Gouden standaard): {mask_match.sum()}\")\n",
    "print(f\"Aantal bruggen NIET gematcht op naam (Terugvallen op KM): {(~mask_match).sum()}\")\n",
    "\n",
    "# --- STAP C: DE LAT/LON BEPALEN ---\n",
    "\n",
    "df_final = df_merged.copy()\n",
    "df_final['source_of_fix'] = 'None'\n",
    "df_final['new_lat'] = np.nan\n",
    "df_final['new_lon'] = np.nan\n",
    "\n",
    "# 1. Voor LRP Matches: Gebruik de Road Lat/Lon (Dit is de beste data!)\n",
    "df_final.loc[mask_match, 'new_lat'] = df_final.loc[mask_match, 'road_lat']\n",
    "df_final.loc[mask_match, 'new_lon'] = df_final.loc[mask_match, 'road_lon']\n",
    "df_final.loc[mask_match, 'source_of_fix'] = 'LRP Name Match'\n",
    "\n",
    "# 2. Voor Niet-Matches: Gebruik Interpolatie op KM (Zoals eerder)\n",
    "# Dit stukje code is iets trager omdat we moeten loopen\n",
    "# We doen dit alleen voor de bruggen waar 'new_lat' nog leeg is\n",
    "missing_mask = df_final['new_lat'].isna()\n",
    "missing_roads = df_final.loc[missing_mask, 'road'].unique()\n",
    "\n",
    "for r in missing_roads:\n",
    "    # Pak road data\n",
    "    r_data = df_roads[df_roads['road'] == r].sort_values('chainage')\n",
    "    if r_data.empty: continue\n",
    "    \n",
    "    # Pak bruggen op deze weg die nog geen fix hebben\n",
    "    sub_mask = (df_final['road'] == r) & (df_final['new_lat'].isna())\n",
    "    kms = df_final.loc[sub_mask, 'km']\n",
    "    \n",
    "    # Interpoleer\n",
    "    df_final.loc[sub_mask, 'new_lat'] = np.interp(kms, r_data['chainage'], r_data['lat'])\n",
    "    df_final.loc[sub_mask, 'new_lon'] = np.interp(kms, r_data['chainage'], r_data['lon'])\n",
    "    df_final.loc[sub_mask, 'source_of_fix'] = 'KM Interpolation'\n",
    "\n",
    "# 3. Checken op verkeerde weg (Analyse vraag van jou)\n",
    "# Als we een LRP Match hebben, maar de KM in BMMS wijkt enorm af van de Chainage in Roads\n",
    "# Dan was de Chainage in BMMS fout (typefout in km)!\n",
    "df_final['km_diff'] = abs(df_final['km'] - df_final['road_chainage'])\n",
    "chainage_typos = df_final[(df_final['source_of_fix'] == 'LRP Name Match') & (df_final['km_diff'] > 1)]\n",
    "\n",
    "print(f\"\\nAantal bruggen waar KM fout was, maar LRP naam ons redde: {len(chainage_typos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3c5763a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Diagnose & Reparatie...\n",
      "Diagnose Voltooid! Dit zijn de problemen in de originele file:\n",
      "Original_Issue\n",
      "Small Offset (50-500m)    8739\n",
      "OK                        6452\n",
      "Large Offset (>500m)      5591\n",
      "Unknown Road               552\n",
      "Missing Coords              30\n",
      "Africa/Ocean                26\n",
      "Zero Coords                 17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Strings\n",
    "df_roads['road'] = df_roads['road'].astype(str).str.strip().str.upper()\n",
    "df_roads['lrp'] = df_roads['lrp'].astype(str).str.strip().str.upper()\n",
    "df_bridges['road'] = df_bridges['road'].astype(str).str.strip().str.upper()\n",
    "df_bridges['LRPName'] = df_bridges['LRPName'].astype(str).str.strip().str.upper()\n",
    "\n",
    "# Nummers\n",
    "for c in ['chainage', 'lat', 'lon']: df_roads[c] = pd.to_numeric(df_roads[c], errors='coerce')\n",
    "for c in ['km', 'lat', 'lon']: df_bridges[c] = pd.to_numeric(df_bridges[c], errors='coerce')\n",
    "\n",
    "print(\"Start Diagnose & Reparatie...\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STAP 1: DE DIAGNOSE (Wat is er mis met de originele data?)\n",
    "# ---------------------------------------------------------\n",
    "df_final = df_bridges.copy()\n",
    "df_final['Original_Issue'] = 'OK' # Startwaarde\n",
    "\n",
    "# A. Check op Null / Zero / Afrika\n",
    "mask_null = df_final['lat'].isna() | df_final['lon'].isna()\n",
    "df_final.loc[mask_null, 'Original_Issue'] = 'Missing Coords'\n",
    "\n",
    "mask_zero = (df_final['lat'] == 0) & (df_final['lon'] == 0)\n",
    "df_final.loc[mask_zero, 'Original_Issue'] = 'Zero Coords'\n",
    "\n",
    "# Alles buiten Lat 20-27 en Lon 88-93 is Afrika/Oceaan\n",
    "mask_africa = (\n",
    "    (df_final['Original_Issue'] == 'OK') & \n",
    "    ((df_final['lat'] < 20) | (df_final['lat'] > 27) | \n",
    "     (df_final['lon'] < 88) | (df_final['lon'] > 93))\n",
    ")\n",
    "df_final.loc[mask_africa, 'Original_Issue'] = 'Africa/Ocean'\n",
    "\n",
    "# B. Check op Offsets (Verkeerde weg / Slechte GPS)\n",
    "# We berekenen waar de brug ZOU moeten zijn volgens KM (Interpolatie)\n",
    "# Dit is puur voor de diagnose, de fix doen we straks pas definitief.\n",
    "df_final['chainage_lat'] = np.nan\n",
    "df_final['chainage_lon'] = np.nan\n",
    "\n",
    "unique_roads = df_final['road'].unique()\n",
    "for r in unique_roads:\n",
    "    r_data = df_roads[df_roads['road'] == r].sort_values('chainage')\n",
    "    if r_data.empty: continue\n",
    "    \n",
    "    mask = df_final['road'] == r\n",
    "    kms = df_final.loc[mask, 'km']\n",
    "    \n",
    "    # Bereken theoretische positie\n",
    "    df_final.loc[mask, 'chainage_lat'] = np.interp(kms, r_data['chainage'], r_data['lat'])\n",
    "    df_final.loc[mask, 'chainage_lon'] = np.interp(kms, r_data['chainage'], r_data['lon'])\n",
    "\n",
    "# Bereken afstand (Haversine) voor diagnose\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000\n",
    "    phi1, phi2 = np.radians(lat1), np.radians(lat2)\n",
    "    dphi = np.radians(lat2 - lat1)\n",
    "    dlambda = np.radians(lon2 - lon1)\n",
    "    a = np.sin(dphi / 2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(dlambda / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "# Alleen checken als GPS geldig is en we de weg kennen\n",
    "mask_calc = (df_final['Original_Issue'] == 'OK') & (~df_final['chainage_lat'].isna())\n",
    "dists = haversine(\n",
    "    df_final.loc[mask_calc, 'lat'], df_final.loc[mask_calc, 'lon'],\n",
    "    df_final.loc[mask_calc, 'chainage_lat'], df_final.loc[mask_calc, 'chainage_lon']\n",
    ")\n",
    "df_final.loc[mask_calc, 'dist_check'] = dists\n",
    "\n",
    "# Markeer grote en kleine offsets\n",
    "large_offset = (df_final['Original_Issue'] == 'OK') & (df_final['dist_check'] > 500)\n",
    "df_final.loc[large_offset, 'Original_Issue'] = 'Large Offset (>500m)'\n",
    "\n",
    "small_offset = (df_final['Original_Issue'] == 'OK') & (df_final['dist_check'] >= 50) & (df_final['dist_check'] <= 500)\n",
    "df_final.loc[small_offset, 'Original_Issue'] = 'Small Offset (50-500m)'\n",
    "\n",
    "# Check Unknown Road\n",
    "mask_unknown = ~df_final['road'].isin(df_roads['road'])\n",
    "df_final.loc[mask_unknown, 'Original_Issue'] = 'Unknown Road'\n",
    "\n",
    "print(\"Diagnose Voltooid! Dit zijn de problemen in de originele file:\")\n",
    "print(df_final['Original_Issue'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f66998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basis diagnose uitvoeren...\n",
      "Chainage vs GPS checken...\n",
      "Geavanceerde analyse voor grote afwijkingen...\n",
      "\n",
      "=== COMPLETE DATA QUALITY ANALYSE ===\n",
      "Issue_Type\n",
      "Small Offset (50-500m)                       8739\n",
      "OK                                           6452\n",
      "Wrong Chainage (On Road, but KM mismatch)    3909\n",
      "GPS Error (Nowhere near any road)            1459\n",
      "Unknown Road (Cannot Check)                   552\n",
      "Likely Wrong Road (Near other road)           223\n",
      "Missing Coords (NaN)                           30\n",
      "Africa/Ocean (GPS Error)                       26\n",
      "Zero Coords (0,0)                              17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#here we added how often the chainage is wrong, so if lon and lat are on the road but the km is wrong, as that km does not belong to that lon and lat \n",
    "#from that followed that the chainge is more wrong so that ofthen the chaina\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "\n",
    "\n",
    "# Strings standaardiseren (Hoofdletters, geen spaties)\n",
    "df_roads['road'] = df_roads['road'].astype(str).str.strip().str.upper()\n",
    "df_bridges['road'] = df_bridges['road'].astype(str).str.strip().str.upper()\n",
    "\n",
    "# Nummers forceren\n",
    "for c in ['chainage', 'lat', 'lon']: df_roads[c] = pd.to_numeric(df_roads[c], errors='coerce')\n",
    "for c in ['km', 'lat', 'lon']: df_bridges[c] = pd.to_numeric(df_bridges[c], errors='coerce')\n",
    "\n",
    "# =============================================================================\n",
    "# 2. BASIS DIAGNOSE (Null, Nul, Afrika)\n",
    "# =============================================================================\n",
    "print(\"Basis diagnose uitvoeren...\")\n",
    "df_final = df_bridges.copy()\n",
    "df_final['Issue_Type'] = 'OK' # We gaan ervan uit dat het goed is, tot tegendeel bewezen\n",
    "\n",
    "# A. Missing Coordinates\n",
    "mask_null = df_final['lat'].isna() | df_final['lon'].isna()\n",
    "df_final.loc[mask_null, 'Issue_Type'] = 'Missing Coords (NaN)'\n",
    "\n",
    "# B. Zero Coordinates (0,0)\n",
    "mask_zero = (df_final['lat'] == 0) & (df_final['lon'] == 0)\n",
    "df_final.loc[mask_zero, 'Issue_Type'] = 'Zero Coords (0,0)'\n",
    "\n",
    "# C. Africa / Out of Bounds\n",
    "# Alles buiten Bangladesh (Lat 20-27, Lon 88-93)\n",
    "mask_africa = (\n",
    "    (df_final['Issue_Type'] == 'OK') & \n",
    "    ((df_final['lat'] < 20) | (df_final['lat'] > 27) | \n",
    "     (df_final['lon'] < 88) | (df_final['lon'] > 93))\n",
    ")\n",
    "df_final.loc[mask_africa, 'Issue_Type'] = 'Africa/Ocean (GPS Error)'\n",
    "\n",
    "# D. Unknown Road (Weg bestaat niet in onze clean.csv)\n",
    "mask_unknown = ~df_final['road'].isin(df_roads['road'])\n",
    "df_final.loc[mask_unknown, 'Issue_Type'] = 'Unknown Road (Cannot Check)'\n",
    "\n",
    "# =============================================================================\n",
    "# 3. CONSISTENTIE CHECK (Chainage vs GPS)\n",
    "# =============================================================================\n",
    "print(\"Chainage vs GPS checken...\")\n",
    "\n",
    "# We berekenen waar de brug ZOU moeten zijn volgens het paaltje (KM)\n",
    "df_final['ideal_lat'] = np.nan\n",
    "df_final['ideal_lon'] = np.nan\n",
    "\n",
    "# Loopje per weg (Interpolatie)\n",
    "unique_roads = df_final.loc[df_final['Issue_Type'] == 'OK', 'road'].unique()\n",
    "\n",
    "for r in unique_roads:\n",
    "    r_data = df_roads[df_roads['road'] == r].sort_values('chainage')\n",
    "    if r_data.empty: continue\n",
    "    \n",
    "    mask = (df_final['road'] == r) & (df_final['Issue_Type'] == 'OK')\n",
    "    kms = df_final.loc[mask, 'km']\n",
    "    \n",
    "    df_final.loc[mask, 'ideal_lat'] = np.interp(kms, r_data['chainage'], r_data['lat'])\n",
    "    df_final.loc[mask, 'ideal_lon'] = np.interp(kms, r_data['chainage'], r_data['lon'])\n",
    "\n",
    "# Haversine Functie (Afstand in meters)\n",
    "def haversine_np(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000\n",
    "    phi1, phi2 = np.radians(lat1), np.radians(lat2)\n",
    "    dphi = np.radians(lat2 - lat1)\n",
    "    dlambda = np.radians(lon2 - lon1)\n",
    "    a = np.sin(dphi / 2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(dlambda / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "# Bereken afstand tussen GPS en Chainage-Punt\n",
    "mask_calc = (df_final['Issue_Type'] == 'OK') & (~df_final['ideal_lat'].isna())\n",
    "dists = haversine_np(\n",
    "    df_final.loc[mask_calc, 'lat'], df_final.loc[mask_calc, 'lon'],\n",
    "    df_final.loc[mask_calc, 'ideal_lat'], df_final.loc[mask_calc, 'ideal_lon']\n",
    ")\n",
    "df_final.loc[mask_calc, 'dist_offset'] = dists\n",
    "\n",
    "# E. Markeer Offsets\n",
    "# Kleine offset (50m - 500m) -> Waarschijnlijk GPS onnauwkeurigheid\n",
    "mask_small = (df_final['Issue_Type'] == 'OK') & (df_final['dist_offset'] >= 50) & (df_final['dist_offset'] <= 500)\n",
    "df_final.loc[mask_small, 'Issue_Type'] = 'Small Offset (50-500m)'\n",
    "\n",
    "# Grote offset (> 500m) -> Hier gaan we dieper op in!\n",
    "mask_large = (df_final['Issue_Type'] == 'OK') & (df_final['dist_offset'] > 500)\n",
    "df_final.loc[mask_large, 'Issue_Type'] = 'Large Offset (>500m)'\n",
    "\n",
    "# =============================================================================\n",
    "# 4. GEAVANCEERDE ANALYSE (Waarom is de offset groot?)\n",
    "# =============================================================================\n",
    "print(\"Geavanceerde analyse voor grote afwijkingen...\")\n",
    "\n",
    "# We pakken alleen de probleemgevallen\n",
    "problem_bridges = df_final[df_final['Issue_Type'] == 'Large Offset (>500m)'].copy()\n",
    "\n",
    "if not problem_bridges.empty:\n",
    "    # 1. Bouw een zoekboom van ALLE punten in het wegennetwerk\n",
    "    # (Dit stelt ons in staat om razendsnel de dichtstbijzijnde weg te vinden)\n",
    "    valid_road_points = df_roads.dropna(subset=['lat', 'lon'])\n",
    "    road_coords = valid_road_points[['lat', 'lon']].values\n",
    "    road_names = valid_road_points['road'].values\n",
    "    \n",
    "    tree = cKDTree(road_coords)\n",
    "    \n",
    "    # 2. Zoek voor elke probleembrug het dichtstbijzijnde punt in HEEL Bangladesh\n",
    "    bridge_coords = problem_bridges[['lat', 'lon']].values\n",
    "    dists_deg, indices = tree.query(bridge_coords)\n",
    "    \n",
    "    # Afstand omrekenen naar meters (1 graad lat is ong 111km)\n",
    "    dists_meters = dists_deg * 111000\n",
    "    nearest_roads = road_names[indices]\n",
    "    \n",
    "    # 3. Classificeren\n",
    "    # F. Wrong Chainage: Brug ligt wél dichtbij (<200m) zijn EIGEN weg, maar chainage klopt niet\n",
    "    mask_wrong_km = (dists_meters < 200) & (nearest_roads == problem_bridges['road'])\n",
    "    \n",
    "    # G. Likely Wrong Road: Brug ligt dichtbij (<200m) een ANDERE weg\n",
    "    mask_wrong_road = (dists_meters < 200) & (nearest_roads != problem_bridges['road'])\n",
    "    \n",
    "    # H. Nowhere: Brug ligt nergens in de buurt (>200m) van welke weg dan ook\n",
    "    mask_nowhere = (dists_meters >= 200)\n",
    "    \n",
    "    # Update de labels in de hoofd-tabel\n",
    "    # We gebruiken de index om de juiste rijen te updaten\n",
    "    df_final.loc[problem_bridges[mask_wrong_km].index, 'Issue_Type'] = 'Wrong Chainage (On Road, but KM mismatch)'\n",
    "    df_final.loc[problem_bridges[mask_wrong_road].index, 'Issue_Type'] = 'Likely Wrong Road (Near other road)'\n",
    "    df_final.loc[problem_bridges[mask_nowhere].index, 'Issue_Type'] = 'GPS Error (Nowhere near any road)'\n",
    "\n",
    "# =============================================================================\n",
    "# 5. RESULTAAT\n",
    "# =============================================================================\n",
    "print(\"\\n=== COMPLETE DATA QUALITY ANALYSE ===\")\n",
    "print(df_final['Issue_Type'].value_counts())\n",
    "\n",
    "# Optioneel: Opslaan om in Excel te bekijken\n",
    "# df_final.to_csv('bridges_diagnosed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c9b34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bezig met diagnosticeren van unmatched bridges...\n",
      "\n",
      "==================================================\n",
      "ANALYSE VAN DE NIET-GEMATCHTE BRUGGEN\n",
      "==================================================\n",
      "Totaal aantal bruggen: 21464\n",
      "Aantal unmatched:      6568 (30.6%)\n",
      "\n",
      "1. WAAROM GEEN MATCH?\n",
      "------------------------------\n",
      "reason\n",
      "LRP Not In Road File      6016\n",
      "Road Not In Clean File     552\n",
      "Name: count, dtype: int64\n",
      "\n",
      "> UITLEG:\n",
      "> 'LRP Not In Road File': De weg is bekend, dus deze kunnen we fixen met interpolatie (chainage).\n",
      "> 'Road Not In Clean File': Deze wegen missen in de road-dataset. Deze bruggen kunnen we NIET fixen.\n",
      "\n",
      "2. HOE ZIET DE DATA VAN DEZE GROEP ERUIT?\n",
      "------------------------------\n",
      "coord_quality\n",
      "Coordinates seem OK (Inside BD)      6440\n",
      "Missing Coordinates (NaN)              94\n",
      "Outside Bangladesh (Africa/Ocean)      17\n",
      "Zero Coordinates (0,0)                 17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "3. KRUISTABEL: REDEN vs KWALITEIT\n",
      "------------------------------\n",
      "coord_quality           Coordinates seem OK (Inside BD)  \\\n",
      "reason                                                    \n",
      "LRP Not In Road File                               5952   \n",
      "Road Not In Clean File                              488   \n",
      "\n",
      "coord_quality           Missing Coordinates (NaN)  \\\n",
      "reason                                              \n",
      "LRP Not In Road File                           30   \n",
      "Road Not In Clean File                         64   \n",
      "\n",
      "coord_quality           Outside Bangladesh (Africa/Ocean)  \\\n",
      "reason                                                      \n",
      "LRP Not In Road File                                   17   \n",
      "Road Not In Clean File                                  0   \n",
      "\n",
      "coord_quality           Zero Coordinates (0,0)  \n",
      "reason                                          \n",
      "LRP Not In Road File                        17  \n",
      "Road Not In Clean File                       0  \n"
     ]
    }
   ],
   "source": [
    "#only for the bridgest that do not match on LRP name, I anaLysed what can be wrong\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STAP 1: VOORBEREIDING\n",
    "# ---------------------------------------------------------\n",
    "# Zorg dat je input dataframes goed staan\n",
    "# We maken kopieën om het origineel niet aan te passen\n",
    "df_b_analysis = df_bridges.copy()\n",
    "df_r_analysis = df_roads.copy()\n",
    "\n",
    "# Uniformeer de kolomnamen en types voor de merge\n",
    "# In clean.csv heet het 'lrp', in bridges 'LRPName' -> wij maken alles 'LRPName'\n",
    "df_r_analysis = df_r_analysis.rename(columns={'lrp': 'LRPName'})\n",
    "\n",
    "# Zorg dat alles strings zijn (voorkomt merge fouten)\n",
    "df_b_analysis['road'] = df_b_analysis['road'].astype(str)\n",
    "df_b_analysis['LRPName'] = df_b_analysis['LRPName'].astype(str)\n",
    "df_r_analysis['road'] = df_r_analysis['road'].astype(str)\n",
    "df_r_analysis['LRPName'] = df_r_analysis['LRPName'].astype(str)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STAP 2: DE SPLITSING (MATCH VS NO-MATCH)\n",
    "# ---------------------------------------------------------\n",
    "# We mergen om te zien wie er wel/niet matcht\n",
    "# We halen alleen 'lat' op uit road file om te checken of er een match is\n",
    "df_merged_check = pd.merge(\n",
    "    df_b_analysis,\n",
    "    df_r_analysis[['road', 'LRPName', 'lat']],\n",
    "    on=['road', 'LRPName'],\n",
    "    how='left',\n",
    "    suffixes=('', '_check')\n",
    ")\n",
    "\n",
    "# Filter: De unmatched groep (waar lat_check leeg is)\n",
    "mask_unmatched = df_merged_check['lat_check'].isna()\n",
    "df_unmatched = df_merged_check[mask_unmatched].copy()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STAP 3: ANALYSE - WAAROM GEEN MATCH?\n",
    "# ---------------------------------------------------------\n",
    "# Lijst van alle wegen die we WEL kennen in de clean file\n",
    "known_roads = set(df_r_analysis['road'].unique())\n",
    "\n",
    "def diagnose_reason(row):\n",
    "    # 1. Bestaat de weg überhaupt in onze clean file?\n",
    "    if row['road'] not in known_roads:\n",
    "        return \"Road Not In Clean File\"\n",
    "    \n",
    "    # 2. Is de LRP naam leeg of nan?\n",
    "    if row['LRPName'] == 'nan' or row['LRPName'] == '' or pd.isna(row['LRPName']):\n",
    "        return \"LRP Name Missing\"\n",
    "    \n",
    "    # 3. Weg bestaat wel, LRP naam is er wel, maar staat niet in de road file\n",
    "    return \"LRP Not In Road File\"\n",
    "\n",
    "print(\"Bezig met diagnosticeren van unmatched bridges...\")\n",
    "df_unmatched['reason'] = df_unmatched.apply(diagnose_reason, axis=1)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STAP 4: ANALYSE - HOE SLECHT ZIJN DE ORIGINELE COÖRDINATEN?\n",
    "# ---------------------------------------------------------\n",
    "# Grenswaarden voor Bangladesh (ongeveer)\n",
    "min_lat, max_lat = 20.5, 26.7\n",
    "min_lon, max_lon = 88.0, 92.9\n",
    "\n",
    "def check_coords(row):\n",
    "    lat = row['lat']\n",
    "    lon = row['lon']\n",
    "    \n",
    "    # Check op NaN\n",
    "    if pd.isna(lat) or pd.isna(lon):\n",
    "        return \"Missing Coordinates (NaN)\"\n",
    "    \n",
    "    # Check op 0,0\n",
    "    if lat == 0 or lon == 0:\n",
    "        return \"Zero Coordinates (0,0)\"\n",
    "    \n",
    "    # Check op Buitenland\n",
    "    if not (min_lat <= lat <= max_lat) or not (min_lon <= lon <= max_lon):\n",
    "        return \"Outside Bangladesh (Africa/Ocean)\"\n",
    "    \n",
    "    # Als het hier komt, lijkt het binnen BD te liggen\n",
    "    return \"Coordinates seem OK (Inside BD)\"\n",
    "\n",
    "df_unmatched['coord_quality'] = df_unmatched.apply(check_coords, axis=1)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STAP 5: PRINT DE RESULTATEN VOOR JE RAPPORT\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ANALYSE VAN DE NIET-GEMATCHTE BRUGGEN\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Totaal aantal bruggen: {len(df_merged_check)}\")\n",
    "print(f\"Aantal unmatched:      {len(df_unmatched)} ({len(df_unmatched)/len(df_merged_check):.1%})\")\n",
    "\n",
    "print(\"\\n1. WAAROM GEEN MATCH?\")\n",
    "print(\"-\" * 30)\n",
    "print(df_unmatched['reason'].value_counts())\n",
    "print(\"\\n> UITLEG:\")\n",
    "print(\"> 'LRP Not In Road File': De weg is bekend, dus deze kunnen we fixen met interpolatie (chainage).\")\n",
    "print(\"> 'Road Not In Clean File': Deze wegen missen in de road-dataset. Deze bruggen kunnen we NIET fixen.\")\n",
    "\n",
    "print(\"\\n2. HOE ZIET DE DATA VAN DEZE GROEP ERUIT?\")\n",
    "print(\"-\" * 30)\n",
    "print(df_unmatched['coord_quality'].value_counts())\n",
    "\n",
    "print(\"\\n3. KRUISTABEL: REDEN vs KWALITEIT\")\n",
    "print(\"-\" * 30)\n",
    "print(pd.crosstab(df_unmatched['reason'], df_unmatched['coord_quality']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e256432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totaal amount of bridges on missing roads: 552\n",
      "----------------------------------------\n",
      "WELKE TYPEN WEGEN MISSEN WE? (Verdeling N, R, Z)\n",
      "road_type\n",
      "Z    402\n",
      "R    150\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#analysis of the bridges with a road name that is missing from the road file \n",
    "# 1. STANDAARDISEER NAMEN (PREPARE COLUMNS)\n",
    "df_bridges['road_norm'] = df_bridges['road'].astype(str).str.strip().str.upper()\n",
    "df_bridges['lrp_norm'] = df_bridges['LRPName'].astype(str).str.strip().str.upper()\n",
    "\n",
    "df_roads['road_norm'] = df_roads['road'].astype(str).str.strip().str.upper()\n",
    "# Check even hoe de kolom heet in jouw clean file (soms 'lrp', soms 'LRPName')\n",
    "if 'lrp' in df_roads.columns:\n",
    "    df_roads['lrp_norm'] = df_roads['lrp'].astype(str).str.strip().str.upper()\n",
    "else:\n",
    "    df_roads['lrp_norm'] = df_roads['LRPName'].astype(str).str.strip().str.upper()\n",
    "\n",
    "# 2. IDENTIFY UNMATCHED BRIDGES\n",
    "merged = df_bridges.merge(\n",
    "    df_roads[['road_norm', 'lrp_norm']], \n",
    "    on=['road_norm', 'lrp_norm'], \n",
    "    how='left', \n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Filter: Pak alleen de bruggen die NIET in de road file zitten\n",
    "unmatched = merged[merged['_merge'] == 'left_only'].copy()\n",
    "\n",
    "# 3. FILTER ALLEEN OP \"ROAD MISSING\"\n",
    "# We maken een set van bekende wegen uit de clean file\n",
    "known_roads = set(df_roads['road_norm'].unique())\n",
    "\n",
    "# We pakken nu direct de subset waar de weg NIET in die set zit\n",
    "missing_roads_df = unmatched[~unmatched['road_norm'].isin(known_roads)].copy()\n",
    "\n",
    "# 4. BEPAAL WEGTYPE (N, R, Z)\n",
    "# Pak de eerste letter van de wegnaam\n",
    "missing_roads_df['road_type'] = missing_roads_df['road_norm'].str[0]\n",
    "\n",
    "# 5. PRINT RESULTAAT\n",
    "print(f\"Totaal amount of bridges on missing roads: {len(missing_roads_df)}\")\n",
    "print(\"-\" * 40)\n",
    "print(\"WELKE TYPEN WEGEN MISSEN WE? (Verdeling N, R, Z)\")\n",
    "print(missing_roads_df['road_type'].value_counts())\n",
    "\n",
    "print(\"-\" * 40)\n",
    "\n",
    "#this shows that the bridges on missing roads are mostly Z ways (so local ways), and some Regional roads but not large important \n",
    "#national highways where a lot of traffic is likely to use the bridge \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "97786bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Onbekende wegen verwijderen...\n",
      "   -> 552 bruggen verwijderd (weg onbekend in clean dataset).\n",
      "   -> 20855 bruggen over om te repareren.\n",
      "3. Lookup tabellen bouwen...\n",
      "4. Uitvoeren 'Golden Match' (LRP Naam)...\n",
      "5. Start reparatie algoritme (Interpolatie & Clamping)...\n",
      "\n",
      "==================================================\n",
      "FINAL REPAIR REPORT\n",
      "==================================================\n",
      "Totaal aantal bruggen verwerkt: 20912\n",
      "\n",
      "1. GEBRUIKTE METHODES:\n",
      "fix_method\n",
      "Fixed: Matched on LRP Name                       14912\n",
      "Fixed: Interpolated by Chainage                   5606\n",
      "Fixed: Chainage > Max Length (Snapped to End)      394\n",
      "Name: count, dtype: int64\n",
      "\n",
      "2. IMPACT VAN DE REPARATIE (VERPLAATSING):\n",
      "Gemiddelde verplaatsing: 17219.7 meter\n",
      "Mediaan verplaatsing:    101.1 meter\n",
      "\n",
      "3. GROTE FOUTEN GECORRIGEERD:\n",
      "Aantal bruggen die >100km verplaatst zijn (Africa/Ocean fixes): 198\n",
      "\n",
      "Bestand opgeslagen als 'bridges_cleaned_final.csv'\n"
     ]
    }
   ],
   "source": [
    "#Solution algorithm wrong\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STAP 1: LADEN EN STANDAARDISEREN\n",
    "# ---------------------------------------------------------\n",
    "def normalize_text(df, col_name):\n",
    "    return df[col_name].astype(str).str.strip().str.upper()\n",
    "# Normaliseer de sleutel-kolommen in beide files\n",
    "df_bridges['road_norm'] = normalize_text(df_bridges, 'road')\n",
    "df_bridges['lrp_norm'] = normalize_text(df_bridges, 'LRPName')\n",
    "\n",
    "df_roads['road_norm'] = normalize_text(df_roads, 'road')\n",
    "# In clean.csv heet de kolom soms 'lrp' of 'LRPName'\n",
    "if 'lrp' in df_roads.columns:\n",
    "    df_roads['lrp_norm'] = normalize_text(df_roads, 'lrp')\n",
    "else:\n",
    "    df_roads['lrp_norm'] = normalize_text(df_roads, 'LRPName')\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STAP 2: FILTER ONBEKENDE WEGEN (CLEAN UP)\n",
    "# ---------------------------------------------------------\n",
    "print(\"2. Onbekende wegen verwijderen...\")\n",
    "known_roads = set(df_roads['road_norm'].unique())\n",
    "\n",
    "# Identificeer bruggen op wegen die niet bestaan in de clean file\n",
    "mask_unknown = ~df_bridges['road_norm'].isin(known_roads)\n",
    "df_dropped = df_bridges[mask_unknown].copy()\n",
    "df_final = df_bridges[~mask_unknown].copy()\n",
    "\n",
    "print(f\"   -> {len(df_dropped)} bruggen verwijderd (weg onbekend in clean dataset).\")\n",
    "print(f\"   -> {len(df_final)} bruggen over om te repareren.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STAP 3: VOORBEREIDING INTERPOLATIE (LOOKUP TABELLEN)\n",
    "# ---------------------------------------------------------\n",
    "print(\"3. Lookup tabellen bouwen...\")\n",
    "# We maken dictionaries voor snelheid. Dit is 100x sneller dan steeds filteren.\n",
    "\n",
    "# A. Max lengte per weg (voor de 'Clamping' check)\n",
    "road_max_lengths = df_roads.groupby('road_norm')['chainage'].max().to_dict()\n",
    "\n",
    "# B. De volledige weg data (chainage, lat, lon) gesorteerd\n",
    "road_dict = {}\n",
    "for road_name, group in df_roads.groupby('road_norm'):\n",
    "    # Zorg dat de wegpunten gesorteerd zijn op chainage!\n",
    "    road_dict[road_name] = group.sort_values('chainage')[['chainage', 'lat', 'lon']]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STAP 4: DE GOUDEN MATCH (LRP NAAM)\n",
    "# ---------------------------------------------------------\n",
    "print(\"4. Uitvoeren 'Golden Match' (LRP Naam)...\")\n",
    "# We mergen de clean road coördinaten erbij\n",
    "df_final = df_final.merge(\n",
    "    df_roads[['road_norm', 'lrp_norm', 'lat', 'lon']], \n",
    "    on=['road_norm', 'lrp_norm'], \n",
    "    how='left', \n",
    "    suffixes=('', '_matched') # '_matched' kolommen komen uit de road file\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STAP 5: DE REPARATIE FUNCTIE (DE CORE LOGICA)\n",
    "# ---------------------------------------------------------\n",
    "print(\"5. Start reparatie algoritme (Interpolatie & Clamping)...\")\n",
    "\n",
    "def repair_bridge_location(row):\n",
    "    # SITUATIE A: Golden Match (LRP Naam klopte)\n",
    "    # -----------------------------------------\n",
    "    if not pd.isna(row['lat_matched']):\n",
    "        # We nemen de coördinaten van de weg over\n",
    "        return row['lat_matched'], row['lon_matched'], \"Fixed: Matched on LRP Name\"\n",
    "    \n",
    "    # SITUATIE B: Geen match, we moeten interpoleren (Chainage)\n",
    "    # ---------------------------------------------------------\n",
    "    road_id = row['road_norm']\n",
    "    km = row['km']\n",
    "    \n",
    "    # Error checks\n",
    "    if pd.isna(km):\n",
    "        return np.nan, np.nan, \"Failed: Missing Chainage\"\n",
    "    \n",
    "    # Haal referentie data op\n",
    "    # (We weten zeker dat road bestaat, want stap 2 filterde de rest weg)\n",
    "    road_data = road_dict[road_id]\n",
    "    max_len = road_max_lengths[road_id]\n",
    "    \n",
    "    # CLAMPING LOGICA (Voorkom dat punten van de kaart vallen)\n",
    "    used_km = km\n",
    "    note = \"Fixed: Interpolated by Chainage\"\n",
    "    \n",
    "    if km < 0:\n",
    "        used_km = 0\n",
    "        note = \"Fixed: Chainage < 0 (Snapped to Start)\"\n",
    "    elif km > max_len:\n",
    "        used_km = max_len\n",
    "        note = \"Fixed: Chainage > Max Length (Snapped to End)\"\n",
    "        \n",
    "    # INTERPOLATIE (De Wiskunde)\n",
    "    # Zoekt de positie van 'used_km' tussen de punten van de weg\n",
    "    new_lat = np.interp(used_km, road_data['chainage'], road_data['lat'])\n",
    "    new_lon = np.interp(used_km, road_data['chainage'], road_data['lon'])\n",
    "    \n",
    "    return new_lat, new_lon, note\n",
    "\n",
    "# Pas de functie toe op elke rij\n",
    "results = df_final.apply(repair_bridge_location, axis=1, result_type='expand')\n",
    "df_final[['lat_clean', 'lon_clean', 'fix_method']] = results\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STAP 6: VALIDATIE & OPSCHONEN\n",
    "# ---------------------------------------------------------\n",
    "# Bereken hoeveel we de brug verplaatst hebben (als check voor je rapport)\n",
    "def haversine_dist(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000\n",
    "    phi1, phi2 = np.radians(lat1), np.radians(lat2)\n",
    "    dphi = np.radians(lat2 - lat1)\n",
    "    dlambda = np.radians(lon2 - lon1)\n",
    "    a = np.sin(dphi/2)**2 + np.cos(phi1)*np.cos(phi2)*np.sin(dlambda/2)**2\n",
    "    return 2 * R * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "\n",
    "# Alleen berekenen als we originele coords hadden\n",
    "mask_has_orig = (~df_final['lat'].isna())\n",
    "df_final.loc[mask_has_orig, 'shift_meters'] = haversine_dist(\n",
    "    df_final.loc[mask_has_orig, 'lat'], \n",
    "    df_final.loc[mask_has_orig, 'lon'], \n",
    "    df_final.loc[mask_has_orig, 'lat_clean'], \n",
    "    df_final.loc[mask_has_orig, 'lon_clean']\n",
    ")\n",
    "\n",
    "# Maak de definitieve export set\n",
    "# We overschrijven de oude lat/lon met de nieuwe 'clean' versie\n",
    "df_export = df_final.copy()\n",
    "df_export['lat'] = df_export['lat_clean']\n",
    "df_export['lon'] = df_export['lon_clean']\n",
    "\n",
    "# Selecteer relevante kolommen\n",
    "export_cols = ['road', 'km', 'type', 'LRPName', 'lat', 'lon', 'fix_method', 'shift_meters', 'condition', 'length']\n",
    "final_output = df_export[export_cols]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STAP 7: RAPPORTAGE\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL REPAIR REPORT\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Totaal aantal bruggen verwerkt: {len(df_final)}\")\n",
    "print(\"\\n1. GEBRUIKTE METHODES:\")\n",
    "print(df_final['fix_method'].value_counts())\n",
    "\n",
    "print(\"\\n2. IMPACT VAN DE REPARATIE (VERPLAATSING):\")\n",
    "print(f\"Gemiddelde verplaatsing: {df_final['shift_meters'].mean():.1f} meter\")\n",
    "print(f\"Mediaan verplaatsing:    {df_final['shift_meters'].median():.1f} meter\")\n",
    "\n",
    "print(\"\\n3. GROTE FOUTEN GECORRIGEERD:\")\n",
    "africa_fixes = (df_final['shift_meters'] > 100000).sum() # > 100km verplaatst\n",
    "print(f\"Aantal bruggen die >100km verplaatst zijn (Africa/Ocean fixes): {africa_fixes}\")\n",
    "\n",
    "# Opslaan\n",
    "final_output.to_csv(\"bridges_cleaned_final.csv\", index=False)\n",
    "print(\"\\nBestand opgeslagen als 'bridges_cleaned_final.csv'\")\n",
    "\n",
    "#see how much chainage exceeded, sth it justifys \n",
    "\n",
    "#major problems: so dont delete the roads, just leave the info there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58e53e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c639ead2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f09451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 20 GROOTSTE CHAINAGE AFWIJKINGEN (in KM):\n",
      " road LRPName    km  Road_Length_Clean_File  Error_KM\n",
      "Z7718 LRP042b 42.35                   8.150    34.200\n",
      "Z7718 LRP042a 42.22                   8.150    34.070\n",
      "Z2813 LRP039a 39.18                   5.240    33.940\n",
      "Z2813 LRP037b 37.81                   5.240    32.570\n",
      "Z2813 LRP037a 37.43                   5.240    32.190\n",
      "Z7718 LRP039d 39.58                   8.150    31.430\n",
      "Z2813 LRP036a 36.40                   5.240    31.160\n",
      "Z7718 LRP039b 39.28                   8.150    31.130\n",
      "Z7718 LRP038a 38.93                   8.150    30.780\n",
      "Z7718 LRP038a 38.93                   8.150    30.780\n",
      "Z2812 LRP035c 35.23                   5.104    30.126\n",
      "Z2812 LRP035a 35.12                   5.104    30.016\n",
      "Z2812 LRP034e 34.98                   5.104    29.876\n",
      "Z2812 LRP034c 34.64                   5.104    29.536\n",
      "Z2812 LRP034d 34.29                   5.104    29.186\n",
      "Z2812 LRP034a 34.01                   5.104    28.906\n",
      "Z2812 LRP033c 33.62                   5.104    28.516\n",
      "Z2812 LRP033b 33.53                   5.104    28.426\n",
      "Z2812 LRP033a 33.14                   5.104    28.036\n",
      "Z2812 LRP032c 32.84                   5.104    27.736\n",
      "Z2812 LRP032b 32.62                   5.104    27.516\n",
      "Z2813 LRP032a 32.54                   5.240    27.300\n",
      "Z2812 LRP032a 32.04                   5.104    26.936\n",
      "Z2812 LRP031e 31.91                   5.104    26.806\n",
      "Z2812 LRP031d 31.83                   5.104    26.726\n",
      "Z2812 LRP031c 31.69                   5.104    26.586\n",
      "Z2812 LRP031b 31.59                   5.104    26.486\n",
      "Z2812 LRP031a 31.29                   5.104    26.186\n",
      "Z2812 LRP030e 30.99                   5.104    25.886\n",
      "Z2813 LRP031a 31.11                   5.240    25.870\n",
      "Z2812 LRP030b 30.83                   5.104    25.726\n",
      "Z2812 LRP030c 30.52                   5.104    25.416\n",
      "Z2812 LRP030a 30.07                   5.104    24.966\n",
      "Z2812 LRP030a 30.07                   5.104    24.966\n",
      "Z2812 LRP029f 29.82                   5.104    24.716\n",
      "Z2812 LRP029f 29.82                   5.104    24.716\n",
      "Z2812 LRP029d 29.27                   5.104    24.166\n",
      "Z2812 LRP029b 29.13                   5.104    24.026\n",
      "Z2812 LRP029b 29.13                   5.104    24.026\n",
      "Z2812 LRP029a 29.08                   5.104    23.976\n",
      "Z2812 LRP028c 28.93                   5.104    23.826\n",
      "Z2812 LRP028b 28.75                   5.104    23.646\n",
      "Z2812 LRP028a 28.00                   5.104    22.896\n",
      "Z2812 LRP027a 27.11                   5.104    22.006\n",
      "Z2812 LRP026d 26.74                   5.104    21.636\n",
      "Z2812 LRP026d 26.74                   5.104    21.636\n",
      "Z2812 LRP026b 26.18                   5.104    21.076\n",
      "Z2812 LRP026a 26.07                   5.104    20.966\n",
      "Z2812 LRP025d 25.96                   5.104    20.856\n",
      "Z2812 LRP025c 25.73                   5.104    20.626\n",
      "Z2812 LRP025b 25.59                   5.104    20.486\n",
      "Z2812 LRP025a 25.07                   5.104    19.966\n",
      "Z2812 LRP024c 24.82                   5.104    19.716\n",
      "Z2813 LRP024c 24.57                   5.240    19.330\n",
      "Z2813 LRP024c 24.51                   5.240    19.270\n",
      "Z2813 LRP024b 24.38                   5.240    19.140\n",
      "Z2812 LRP024a 24.15                   5.104    19.046\n",
      "Z2812 LRP024a 24.15                   5.104    19.046\n",
      "Z2813 LRP024a 24.14                   5.240    18.900\n",
      "Z2813 LRP023c 23.93                   5.240    18.690\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#This checks the chainage mistakes and further analysis them\n",
    "# for the roads with wrong chainage, so chainage out of bounds of the road length \n",
    "#What the mistake looks like the result shows that it might be filled in in meters instead of KM so /10 error\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# TABEL: ANALYSE VAN CHAINAGE FOUTEN (TOP 20)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# 1. Bepaal de maximale lengte van elke weg in de clean road file\n",
    "road_max_lengths = df_roads.groupby('road_norm')['chainage'].max().reset_index()\n",
    "road_max_lengths.columns = ['road_norm', 'Road_Length_Clean_File']\n",
    "\n",
    "# 2. Filter de bruggen die we naar het einde hebben getrokken (Snapped to End)\n",
    "# We gebruiken df_work of df_final uit je vorige stappen\n",
    "df_errors = df_final[df_final['fix_method'].str.contains(\"Snapped to End\", na=False)].copy()\n",
    "\n",
    "# 3. Voeg de weglengte toe aan de bruggen-tabel\n",
    "df_errors = df_errors.merge(road_max_lengths, on='road_norm', how='left')\n",
    "\n",
    "# 4. Bereken het verschil (de fout)\n",
    "df_errors['Error_KM'] = df_errors['km'] - df_errors['Road_Length_Clean_File']\n",
    "\n",
    "# 5. Maak de tabel toonbaar\n",
    "# We kiezen de belangrijkste kolommen om te inspecteren\n",
    "tabel_kolommen = [\n",
    "    'road', \n",
    "    'LRPName', \n",
    "    'km', \n",
    "    'Road_Length_Clean_File', \n",
    "    'Error_KM'\n",
    "]\n",
    "\n",
    "# Sorteer van hoog naar laag op basis van de fout\n",
    "fouten_tabel = df_errors[tabel_kolommen].sort_values(by='Error_KM', ascending=False)\n",
    "\n",
    "print(\"TOP 20 GROOTSTE CHAINAGE AFWIJKINGEN (in KM):\")\n",
    "print(fouten_tabel.head(60).to_string(index=False))\n",
    "\n",
    "# Optioneel: Sla deze lijst op om later aan je docent te laten zien\n",
    "# fouten_tabel.to_csv(\"chainage_errors_analysis.csv\", index=False) \n",
    "\n",
    "#It looks like the comma was misplaced so we have to keep that in mind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "68dd0ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SAFETY CHECK: RATIO ANALYSE ---\n",
      "Safety_Check\n",
      "RISICO: Kleine overshoot (Snap to End is beter)    264\n",
      "VEILIG: Duidelijke Typo (Factor 10+)               147\n",
      "Name: count, dtype: int64\n",
      "\n",
      "VOORBEELDEN VAN RISICO GEVALLEN (Niet delen door 10!):\n",
      "     road       km  length\n",
      "1704   N7  249.754     2.2\n",
      "1705   N7  250.336     2.4\n",
      "1706   N7  250.512     2.2\n",
      "1707   N7  251.068     2.2\n",
      "1708   N7  251.434     2.8\n"
     ]
    }
   ],
   "source": [
    "#this shows how often snap to road how often km to meters \n",
    "#so with chainage mistake, it can be a small mistake, so like little bit outside the road range, then it does snap to end \n",
    "# but when /10 makes more sense (so mistake of meters instead of km, it changes the chainage to meters) \n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# SAFETY CHECK: HEBBEN WE 'GEVAARLIJKE' CORRECTIES?\n",
    "# ---------------------------------------------------------\n",
    "print(\"--- SAFETY CHECK: RATIO ANALYSE ---\")\n",
    "\n",
    "# We gebruiken weer road_max_lengths\n",
    "road_max_lengths = df_roads.groupby('road_norm')['chainage'].max().to_dict()\n",
    "\n",
    "def analyze_ratio(row):\n",
    "    road_id = row['road_norm']\n",
    "    km = row['km']\n",
    "    \n",
    "    if road_id not in road_max_lengths or pd.isna(km): return \"Skip\"\n",
    "    max_len = road_max_lengths[road_id]\n",
    "    \n",
    "    if km <= max_len: return \"OK\"\n",
    "    \n",
    "    # Bereken de ratio: Hoeveel keer groter is de chainage dan de weg?\n",
    "    ratio = km / max_len\n",
    "    \n",
    "    # Check of /10 zou passen\n",
    "    fits_div_10 = (km / 10.0) <= max_len\n",
    "    \n",
    "    if fits_div_10:\n",
    "        if ratio < 1.5:\n",
    "            return \"RISICO: Kleine overshoot (Snap to End is beter)\"\n",
    "        else:\n",
    "            return \"VEILIG: Duidelijke Typo (Factor 10+)\"\n",
    "    else:\n",
    "        return \"NO FIT: Ook /10 past niet\"\n",
    "\n",
    "# Voer de check uit op de probleemgevallen\n",
    "df_safety = df_final[df_final['km'] > 0].copy()\n",
    "df_safety['Safety_Check'] = df_safety.apply(analyze_ratio, axis=1)\n",
    "\n",
    "# Filter op de problemen\n",
    "risk_analysis = df_safety[df_safety['Safety_Check'].str.contains(\"RISICO|VEILIG\")]\n",
    "\n",
    "print(risk_analysis['Safety_Check'].value_counts())\n",
    "\n",
    "print(\"\\nVOORBEELDEN VAN RISICO GEVALLEN (Niet delen door 10!):\")\n",
    "print(risk_analysis[risk_analysis['Safety_Check'].str.contains(\"RISICO\")][['road', 'km', 'length']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7684c1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Onbekende wegen verwijderen en roads opschonen...\n",
      "   -> 552 bruggen verwijderd (weg onbekend).\n",
      "   -> 20855 bruggen over.\n",
      "3. Lookup tabellen bouwen...\n",
      "4. Uitvoeren 'Golden Match' (LRP Naam)...\n",
      "5. Start reparatie (LRP -> Chainage -> Smart Typo -> Snap)...\n",
      "6. Opslaan als Excel (Sheet: BMMS_overview)...\n",
      "\n",
      "==================================================\n",
      "SUCCESS!\n",
      "==================================================\n",
      "fix_method\n",
      "Fixed: Matched on LRP Name                 14855\n",
      "Fixed: Interpolated by Chainage             5610\n",
      "Fixed: Typo detected (Chainage / 10)         260\n",
      "Fixed: Snapped to End (Small deviation)      134\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Bestand opgeslagen: BMMS_overview_CLEANED.xlsx\n",
      "Tabblad naam: BMMS_overview\n"
     ]
    }
   ],
   "source": [
    "#final algorithm that makes clean data set: \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalize_text(df, col_name):\n",
    "    return df[col_name].astype(str).str.strip().str.upper()\n",
    "# Normaliseer de sleutel-kolommen in beide files\n",
    "df_bridges['road_norm'] = normalize_text(df_bridges, 'road')\n",
    "df_bridges['lrp_norm'] = normalize_text(df_bridges, 'LRPName')\n",
    "\n",
    "df_roads['road_norm'] = normalize_text(df_roads, 'road')\n",
    "# In clean.csv heet de kolom soms 'lrp' of 'LRPName'\n",
    "if 'lrp' in df_roads.columns:\n",
    "    df_roads['lrp_norm'] = normalize_text(df_roads, 'lrp')\n",
    "else:\n",
    "    df_roads['lrp_norm'] = normalize_text(df_roads, 'LRPName')\n",
    "\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# STAP 2: WEGEN OPSCHONEN & FILTEREN\n",
    "# =========================================================\n",
    "print(\"2. Onbekende wegen verwijderen en roads opschonen...\")\n",
    "\n",
    "# Sorteer wegen (nodig voor interpolatie)\n",
    "df_roads = df_roads.sort_values(by=['road_norm', 'chainage'])\n",
    "df_roads = df_roads.drop_duplicates(subset=['road_norm', 'chainage'], keep='first')\n",
    "\n",
    "# Filter bruggen op onbekende wegen\n",
    "known_roads = set(df_roads['road_norm'].unique())\n",
    "original_count = len(df_bridges)\n",
    "df_final = df_bridges[df_bridges['road_norm'].isin(known_roads)].copy()\n",
    "\n",
    "print(f\"   -> {original_count - len(df_final)} bruggen verwijderd (weg onbekend).\")\n",
    "print(f\"   -> {len(df_final)} bruggen over.\")\n",
    "\n",
    "# =========================================================\n",
    "# STAP 3: LOOKUP TABELLEN BOUWEN\n",
    "# =========================================================\n",
    "print(\"3. Lookup tabellen bouwen...\")\n",
    "road_max_lengths = df_roads.groupby('road_norm')['chainage'].max().to_dict()\n",
    "\n",
    "road_dict = {}\n",
    "for road_name, group in df_roads.groupby('road_norm'):\n",
    "    road_dict[road_name] = group[['chainage', 'lat', 'lon']]\n",
    "\n",
    "# =========================================================\n",
    "# STAP 4: DE GOUDEN MATCH (LRP NAAM)\n",
    "# =========================================================\n",
    "print(\"4. Uitvoeren 'Golden Match' (LRP Naam)...\")\n",
    "df_final = df_final.merge(\n",
    "    df_roads[['road_norm', 'lrp_norm', 'lat', 'lon']], \n",
    "    on=['road_norm', 'lrp_norm'], \n",
    "    how='left', \n",
    "    suffixes=('', '_matched')\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# STAP 5: DE INTELLIGENTE REPARATIE\n",
    "# =========================================================\n",
    "print(\"5. Start reparatie (LRP -> Chainage -> Smart Typo -> Snap)...\")\n",
    "\n",
    "def repair_bridge_location_final(row):\n",
    "    # 1. LRP MATCH (Goud)\n",
    "    if not pd.isna(row['lat_matched']):\n",
    "        return row['lat_matched'], row['lon_matched'], \"Fixed: Matched on LRP Name\"\n",
    "    \n",
    "    road_id = row['road_norm']\n",
    "    km = row['km']\n",
    "    \n",
    "    if pd.isna(km) or road_id not in road_dict:\n",
    "        return row['lat'], row['lon'], \"Error: Data missing\"\n",
    "\n",
    "    road_data = road_dict[road_id]\n",
    "    max_len = road_max_lengths[road_id]\n",
    "\n",
    "    # 2. CHAINAGE IS GOED (Zilver)\n",
    "    if 0 <= km <= max_len:\n",
    "        new_lat = np.interp(km, road_data['chainage'], road_data['lat'])\n",
    "        new_lon = np.interp(km, road_data['chainage'], road_data['lon'])\n",
    "        return new_lat, new_lon, \"Fixed: Interpolated by Chainage\"\n",
    "\n",
    "    # 3. CHAINAGE FOUT (Brons / Fallback)\n",
    "    \n",
    "    # A. Kleine afwijking (Meetruis) -> Snap to End\n",
    "    if km < (max_len * 1.1) or (km - max_len) < 1.0:\n",
    "        lat_end = np.interp(max_len, road_data['chainage'], road_data['lat'])\n",
    "        lon_end = np.interp(max_len, road_data['chainage'], road_data['lon'])\n",
    "        return lat_end, lon_end, \"Fixed: Snapped to End (Small deviation)\"\n",
    "\n",
    "    # B. Grote afwijking -> Check Typo (Factor 10)\n",
    "    km_div_10 = km / 10.0\n",
    "    if km_div_10 <= max_len:\n",
    "        lat_10 = np.interp(km_div_10, road_data['chainage'], road_data['lat'])\n",
    "        lon_10 = np.interp(km_div_10, road_data['chainage'], road_data['lon'])\n",
    "        return lat_10, lon_10, \"Fixed: Typo detected (Chainage / 10)\"\n",
    "\n",
    "    # C. Fallback (Nog steeds te groot) -> Snap to End\n",
    "    used_km = max(0, min(km, max_len)) # Clamp\n",
    "    new_lat = np.interp(used_km, road_data['chainage'], road_data['lat'])\n",
    "    new_lon = np.interp(used_km, road_data['chainage'], road_data['lon'])\n",
    "    return new_lat, new_lon, \"Fixed: Snapped to End (Road too short)\"\n",
    "\n",
    "# Voer uit\n",
    "results = df_final.apply(repair_bridge_location_final, axis=1, result_type='expand')\n",
    "df_final[['lat_clean', 'lon_clean', 'fix_method']] = results\n",
    "\n",
    "# =========================================================\n",
    "# STAP 6: EXPORT NAAR EXCEL\n",
    "# =========================================================\n",
    "print(f\"6. Opslaan als Excel (Sheet: {SHEET_NAME})...\")\n",
    "\n",
    "original_columns = [\n",
    "    'road', 'km', 'type', 'LRPName', 'name', 'length', 'condition', 'structureNr', \n",
    "    'roadName', 'chainage', 'width', 'constructionYear', 'spans', 'zone', \n",
    "    'circle', 'division', 'sub-division', 'lat', 'lon', 'EstimatedLoc'\n",
    "]\n",
    "\n",
    "df_export = df_final.copy()\n",
    "df_export['lat'] = df_export['lat_clean']\n",
    "df_export['lon'] = df_export['lon_clean']\n",
    "df_export['EstimatedLoc'] = df_export['fix_method']\n",
    "\n",
    "# Zorg dat numerieke kolommen schoon zijn\n",
    "for col in ['lat', 'lon', 'km', 'length']:\n",
    "    df_export[col] = pd.to_numeric(df_export[col], errors='coerce')\n",
    "\n",
    "df_export = df_export[original_columns]\n",
    "\n",
    "# HIER IS DE FIX: sheet_name=\"BMMS_overview\"\n",
    "df_export.to_excel(OUTPUT_FILE, index=False, sheet_name=SHEET_NAME)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUCCESS!\")\n",
    "print(\"=\"*50)\n",
    "print(df_final['fix_method'].value_counts())\n",
    "print(f\"\\nBestand opgeslagen: {OUTPUT_FILE}\")\n",
    "print(f\"Tabblad naam: {SHEET_NAME}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c1049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe7e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb39810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d157c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7788789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
